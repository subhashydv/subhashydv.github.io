<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><title>Agentic AI ‚Äì Personal RAG System -
Hugo Atlantic</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=https://subhashydv.github.io/favicon-32x32.png><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Fira+Mono&family=Lato:wght@300;400;700&family=Source+Sans+Pro&display=swap" rel=stylesheet><meta name=description content="An overview to creating a chatbot that can ingest PDF or TXT documents and answer questions directly from their content. It integrates with the MCP protocol to serve knowledge directly to AI tools."><meta property="og:title" content="Agentic AI ‚Äì Personal RAG System"><meta property="og:type" content="website"><meta property="og:url" content="https://subhashydv.github.io/blog/2025/09/agentic-ai-personal-rag-system/"><meta property="og:image" content="https://subhashydv.github.io/images/agentic-ai-1.jpg"><meta property="og:description" content="An overview to creating a chatbot that can ingest PDF or TXT documents and answer questions directly from their content. It integrates with the MCP protocol to serve knowledge directly to AI tools."><meta name=twitter:card content="summary"><meta name=twitter:site content="@zerostaticio"><meta name=twitter:creator content="@zerostaticio"><link rel=stylesheet href="/css/dist/style.min.efc526e68ba78a4bf585989fdfdb3dcc64e53878fd2c9676a72beca9a8bde216.css" integrity="sha256-78Um5ounikv1hZif39s9zGTlOHj9LJZ2pyvsqai94hY="></head><body class=page><div id=menu-container class="bg-blue-600 h-screen w-screen fixed z-50 py-6 bg-gradient-to-b from-green-400 to-blue-500 opacity-90 overflow-hidden hidden"><div class="container mx-auto px-6 md:px-4 relative flex flex-col items-center justify-around"><div id=menu-close role=button class="top-1 right-5 absolute hover:opacity-70 cursor:pointer text-white"><svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 48 48"><path fill="currentcolor" d="M39.486328 6.9785156a1.50015 1.50015.0 00-1.046875.4609375L24 21.878906 9.5605469 7.4394531A1.50015 1.50015.0 008.484375 6.984375 1.50015 1.50015.0 007.4394531 9.5605469L21.878906 24 7.4394531 38.439453a1.50015 1.50015.0 102.1210938 2.121094L24 26.121094 38.439453 40.560547a1.50015 1.50015.0 102.121094-2.121094L26.121094 24 40.560547 9.5605469A1.50015 1.50015.0 0039.486328 6.9785156z"/></svg></div><div class="flex flex-col text-center text-white text-3xl font-light"><a class="py-2 hover:opacity-70" href=/>Home</a>
<a class="py-2 hover:opacity-70" href=/posts/>Blog</a>
<a class="py-2 hover:opacity-70" href=/about/>About</a></div></div></div><div class="container mx-auto px-6 md:px-4"><header class="flex bg-white items-center justify-between py-6"><div class="hidden md:block"><a class="flex items-center hover:opacity-70 transition duration-300 ease-in-out" href=https://subhashydv.github.io/><img class=mr-2 height=100 width=100 alt=" Logo" src=/images/logo/logo.png><h2 class="text-2xl font-sans font-semibold">Supreme Viki</h2></a></div><div class="block md:hidden"><a class="flex items-center hover:opacity-70 transition duration-300 ease-in-out" href=https://subhashydv.github.io/><img height=100 width=100 alt=" Logo" src=/images/logo/logo.png><h2 class="text-2xl font-sans font-semibold">Supreme Viki</h2></a></div><button class="hover:opacity-70 transition duration-300 ease-in-out text-black" id=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 48 48"><path fill="currentcolor" d="M5.5 9a1.50015 1.50015.0 100 3h37a1.50015 1.50015.0 100-3H5.5zm0 13.5a1.50015 1.50015.0 100 3h37a1.50015 1.50015.0 100-3H5.5zM5.5 36a1.50015 1.50015.0 100 3h37a1.50015 1.50015.0 100-3H5.5z"/></svg></button></header><div class="heading py-6 md:py-12 lg:w-10/12 md:text-center mx-auto"><div class="font-medium text-gray-700">Sep 7, 2025</div><h1 class="heading text-4xl md:text-6xl font-bold font-sans md:leading-tight">Agentic AI ‚Äì Personal RAG System</h1><h2 class="text-xl text-gray-600 mt-2">An overview to creating a chatbot that can ingest PDF or TXT documents and answer questions directly from their content. It integrates with the MCP protocol to serve knowledge directly to AI tools.</h2></div><img width=600 height=600 src=/images/agentic-ai-1.jpg><div class="flex flex-col md:flex-row py-6 md:py-12"><div class="w-full md:w-3/12 pr-3"><div class="hidden md:block"><a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/tech>Tech</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/tutorial>Tutorial</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/ai>AI</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/ai-agent>AI Agent</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/rag-modal>RAG Modal</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/mcp-server>MCP Server</a></div></div><div class="w-full md:w-9/12"><div class=prose><p>With all the noise around on AI these days, it‚Äôs easy for developers especially beginners to feel overwhelmed. Questions like ‚ÄúHow do I start learning AI?‚Äù or ‚ÄúWhere should I begin?‚Äù are common. If you‚Äôre asking yourself the same, you‚Äôre in the right place. This blog is designed specifically for beginners and will walk you through the basics to help you take your first steps into the world of Agentic AI.</p><h2 id=intro->Intro :</h2><p>In this post, I‚Äôll walk you through how I created a personal chatbot powered by Retrieval Augmented Generation (RAG). This chatbot can take a PDF or TXT file, understand its context, and answer your questions using the provided context.</p><p>To make it even more useful, I have also added MCP (Model Context Protocol) server functionality, so it can be plugged into AI assistants like github-copilot.</p><p>The complete code is available on GitHub ‚Äî feel free to use it as a reference üëâ <a href=https://github.com/subhashydv/personal-ai-chatbot>Link Here</a></p><h2 id=what-is-rag->What is RAG :</h2><p>Traditional LLMs answer questions from their training data and it can be outdated. Whereas RAG system enrich LLMs by providing relevant data from external knowledge base (like pdf, txt or Database). The LLM then answer based on retrieved context.</p><p><em>Now, I&rsquo;ll walk you through the architecture.</em></p><h2 id=architecture->Architecture :</h2><p><img src=/images/ai-architecture.png alt=architecture></p><p><em>Let&rsquo;s understand the core part (APP) first :</em></p><h3 id=upload->Upload :</h3><p>It&rsquo;s an exposed rest api in our application to upload a pdf or txt file from which we want to ask questions. We can extend it further to upload context from other data formats.</p><h3 id=preprocessor->Preprocessor :</h3><p>Preprocessor are going to parse the data and convert into a format(ie. json or txt), in which application can easily process the data further. Tools like pdf-reader can be used.</p><h3 id=chunking->Chunking :</h3><p>After parsing the data, the next step is to split it into manageable chunks. This ensures that when providing context to the LLM, only the most relevant chunks are passed instead of unnecessary data. The text should be split in a way that related chunks can be retrieved easily during a query. The chunk size depends on both the application requirements and the type of data being processed. Additionally, using a chunk overlap helps in maintaining context across adjacent chunk.</p><p>Tools like <strong>LangChain‚Äôs TextSplitter</strong> can be used for Chunking.
Code example :</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>import { RecursiveCharacterTextSplitter } from &#34;langchain/text_splitter&#34;;
</span></span><span class=line><span class=cl>const splitter = new RecursiveCharacterTextSplitter({chunkSize: 1000, chunkOverlap: 100});
</span></span><span class=line><span class=cl>await splitter.splitText(text)
</span></span></code></pre></div><h3 id=embedding->Embedding :</h3><p>After splitting chunks, we need to create embedding for each chunk. An embedding is a numerical representation of text designed to be consumed by semantic search algorithms. These embeddings are stored in a vector database so we can quickly retrieve the most relevant chunks later.
For embedding tools like @xenova/transformers or OpenAI embeddings can be used.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>import { pipeline } from &#39;@xenova/transformers&#39;;
</span></span><span class=line><span class=cl>const embedder = await pipeline(&#39;feature-extraction&#39;, &#39;Xenova/all-MiniLM-L6-v2&#39;);
</span></span><span class=line><span class=cl>const emb = await embedder(chunks[0], { pooling: &#39;mean&#39;, normalize: true }); // only for first chunk (do it for all)
</span></span></code></pre></div><h3 id=vector-store->Vector Store :</h3><p>A vector store is a special type of database used to save embeddings. When a user asks a question, the system looks up the most similar vectors in the store and retrieves the related chunks.
Popular vector stores are Chroma, Faiss and Pinecone.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// Install Chroma
</span></span><span class=line><span class=cl>chroma run 
</span></span><span class=line><span class=cl>// Use it to save embeddings
</span></span></code></pre></div><h3 id=ask->Ask :</h3><p>Similar to upload it&rsquo;s an exposed rest api in our application to ask questions from provided context. This Api will return response from only provided context.</p><h3 id=orchestrator->Orchestrator :</h3><p>When the application receives the user query, it generates the embedding of the query and uses it to retrieves the most relevant chunks(number of chunks can be specified) from the vector store. These retrieved chunks, along with user query and custom prompt are then passed to LLM for summarizing and rephrasing of the response.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>import OpenAI from &#34;openai&#34;;
</span></span><span class=line><span class=cl>const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>await openai.chat.completions.create({
</span></span><span class=line><span class=cl>    model: &#34;gpt-4o-mini&#34;,
</span></span><span class=line><span class=cl>    messages: [
</span></span><span class=line><span class=cl>      {
</span></span><span class=line><span class=cl>        role: &#34;system&#34;,
</span></span><span class=line><span class=cl>        content: &#34;You are a personal knowledge assistant. Use only the provided context to answer.&#34;
</span></span><span class=line><span class=cl>      },
</span></span><span class=line><span class=cl>      {
</span></span><span class=line><span class=cl>        role: &#34;user&#34;,
</span></span><span class=line><span class=cl>        content: `Context:\n${retrievedChunks}\n\nQuestion: ${userQuestion}`
</span></span><span class=line><span class=cl>      }
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>  });
</span></span></code></pre></div><h3 id=llm->LLM :</h3><p>Here, LLM (large language modal) role is to process the given prompt, which includes retrieved context, user query and custom prompt. it than generates a summarized and well-phrased response which can be responded to user.</p><p>LLM modals are : GPT-4, LLaMA etc.</p><p><em>üéâ Now we have an ready to use RAG modal, which can answer questions from provided context üéâ</em></p><p><em>Let&rsquo;s move to connecting it with a tool which can communicate with it :</em></p><h2 id=mcp-server->MCP Server :</h2><p>An MCP server, or Model Context Protocol server, is a program that exposes specific capabilities and resources to AI applications, particularly Large Language Models (LLMs) and AI agents, through a standardized protocol. It acts as an intermediary, allowing AI models to securely interact with external tools and data sources.</p><p>Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.</p><p><em>Here we will be using MCP server to connect with /ask rest endpoint. You can find the code <a href=https://github.com/subhashydv/personal-ai-chatbot/blob/main/mcp/server.js>here</a></em></p></div></div></div><div class="py-6 mt-6 border-t-2 block md:hidden"><h3 class="text-sm font-medium mb-1">Categories</h3><div><a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/tech>Tech</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/tutorial>Tutorial</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/ai>AI</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/ai-agent>AI Agent</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/rag-modal>RAG Modal</a>
<a class="p-1 px-3 mr-1 mb-1 inline-block text-xs font-mono rounded bg-green-200 text-green-800 hover:bg-blue-200 hover:text-blue-800 transition duration-300 ease-in-out" href=/categories/mcp-server>MCP Server</a></div></div><footer class="py-6 border-t-2"><div class="container mx-auto"><div class="flex mb-2"><a class="py-2 mr-2" href=https://github.com/subhashydv><img width=24 height=24 src=https://simpleicons.org/icons/github.svg alt=Github></a></div><div class="text-sm text-gray-600"><span>By Subhash</span>
<a class=text-green-500 href=https://github.com/subhashydv>github</a></div></footer></div><script type=text/javascript src=/js/bundle.min.7d96da6b346104485ed09a6021bb756b653326d73ed3adac0c40a160ce0a4e52.js></script></body></html>